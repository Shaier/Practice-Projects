{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cat_Vs_Dog.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Mf8lSltGMIPO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Mount my drive- run the code, go to the link, accept.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tFGj5u83ML9z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b54acd70-06d4-4811-b993-ea585f0a9fc9"
      },
      "cell_type": "code",
      "source": [
        "#Change working directory to make it easier to access the files- (Folder inside of Colab- CNN folder- Images- Train/Test folder- Inside of each there are bunny/dog folders) \n",
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs\")\n",
        "os.getcwd() "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "YSn2H_TEMw6_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a43e8ef-94d2-4c12-a326-8430eabc9fbd"
      },
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import time\n",
        "import h5py\n",
        "import csv\n",
        "\n",
        "from scipy.misc import imresize, imsave\n",
        "\n",
        "from sklearn.metrics import log_loss, confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from PIL import Image, ImageChops, ImageOps\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping, Callback\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, Activation, Dropout, Flatten, Dense"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "MYoY8qtGM-BP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Moving all the cat pictures to a cat folder so they'll be a happy family\n",
        "#Moving all the dog pictures to a dog folder because the cats told me to\n",
        "\n",
        "import os, shutil\n",
        "path = \"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train\"\n",
        "movetodog = \"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/Dogs\"\n",
        "movetocat='/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/Cats'\n",
        "files = os.listdir(path)\n",
        "files.sort()\n",
        "for f in files:\n",
        "  if \"cat\" in f:\n",
        "    src = os.path.join(path, f)\n",
        "    dst = os.path.join(movetocat, f)\n",
        "    shutil.move(src,dst)\n",
        "  elif \"dog\" in f:\n",
        "    src = os.path.join(path, f)\n",
        "    dst = os.path.join(movetodog, f)\n",
        "    shutil.move(src,dst)\n",
        "  else: pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rv9MOSoJPB4J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c7405068-4490-483f-e0de-448237da165b"
      },
      "cell_type": "code",
      "source": [
        "#Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "\n",
        "#Step 1- Convolution\n",
        "#Make 32 feature detectors (filters/kernels) with a size of 3x3\n",
        "#Choose the input-image's format to be 64x64 with 3 channels\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape=(256, 256, 3), activation=\"relu\"))\n",
        "\n",
        "# Step 2 - Pooling - the window is 2x2 pixels\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Adding a second convolutional layer\n",
        "#Make 32 feature detectors (filters/kernels) with a size of 3x3\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2))) #the window is 2x2 pixels\n",
        "\n",
        "# Step 3 - Flattening- transforming the NxN matrix to Nx1 (A.K.A 1 column)\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Step 4 - Full connection - \"units\" is the dimensionality of the output space - so here we send it to 128 neurons and then all of those go to 1 neuron\n",
        "classifier.add(Dense(activation=\"relu\", units=128))\n",
        "classifier.add(Dense(activation=\"sigmoid\", units=1))\n",
        "\n",
        "# Compiling the CNN\n",
        "classifier.compile(optimizer =Adam(lr=0.001), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# use ImageDataGenerator to preprocess the data\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#Augment the data so we can \"create\" a larger dataset\n",
        "\n",
        "#rescale: rescaling factor. Defaults to None. If None or 0, no rescaling is applied, otherwise we multiply the data by the value provided (after applying all other transformations).\n",
        "#shear_range: Float. Shear Intensity (Shear angle in counter-clockwise direction in degrees)\n",
        "#zoom_range: Float or [lower, upper]. Range for random zoom.\n",
        "#horizontal_flip: Boolean. Randomly flip inputs horizontally\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "#Prepare the training data:\n",
        "\n",
        "#1st input is the directory where the different folders of images are (folder of bunnies, folder of dogs here)\n",
        "#2nd input is target_size=  tuple of integers (height, width) - default: `(256, 256)`. The dimensions to which all images found will be resized.\n",
        "#3rd input is batch= size of the batches of data (default: 32).One of \"categorical\", \"binary\", \"sparse\", \"input\", or None. Default: \"categorical\". Determines the type of label arrays that are returned:\n",
        "#\"categorical\" will be 2D one-hot encoded labels, \"binary\" will be 1D binary labels, \"sparse\" will be 1D integer labels, \"input\" will be images identical to input images (mainly used to work with autoencoders).\n",
        "#If None, no labels are returned (the generator will only yield batches of image data, which is useful to use with model.predict_generator(),  model.evaluate_generator(), etc.). Please note that in case of class_mode None, the data still needs to reside in a subdirectory of directory for it to work correctly.\n",
        "#Note that you can also subset it here with \"subset\"- to create validation / training \n",
        "#batch_size determines the number of samples in each mini batch. Its maximum is the number of all samples, which makes gradient descent accurate, the loss will decrease towards the minimum if the learning rate is small enough, but iterations are slower. Its minimum is 1, resulting in stochastic gradient descent: Fast but the direction of the gradient step is based only on one example, the loss may jump around.\n",
        "training_data = train_datagen.flow_from_directory('./train',\n",
        "                                                 target_size = (256, 256),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "#Prepare the test data\n",
        "\n",
        "test_data = test_datagen.flow_from_directory('./train',\n",
        "                                            target_size = (256, 256),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')\n",
        "\n",
        "#Start the computation\n",
        "#Generator- a python training data batch generator; endlessly looping over its training data\n",
        "#steps_per_epoch the number of batch iterations before a training epoch is considered finished. If you have a training set of fixed size you can ignore it but it may be useful if you have a huge data set or if you are generating random data augmentations on the fly, i.e. if your training set has a (generated) infinite size.\n",
        "#validation_steps similar to steps_per_epoch but on the validation data set instead on the training data. If you have the time to go through your whole validation data set I recommend to skip this parameter.\n",
        "#To improve the model accuracy you can increase the number of steps_per_epoch to e.g. 8000\n",
        "#The number of samples processed for each epoch is batch_size * steps_per_epochs (here the batch size is 32, so the samples processed will be 8000 per epoch)\n",
        "\n",
        "classifier.fit_generator(training_data,\n",
        "                         steps_per_epoch = (2000 / 32),\n",
        "                         epochs = 2,\n",
        "                         validation_data = test_data,\n",
        "                         validation_steps = 2000/32)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 images belonging to 2 classes.\n",
            "Found 25000 images belonging to 2 classes.\n",
            "Epoch 1/2\n",
            "63/62 [==============================] - 906s 14s/step - loss: 0.9228 - acc: 0.5184 - val_loss: 0.6845 - val_acc: 0.5749\n",
            "Epoch 2/2\n",
            "63/62 [==============================] - 728s 12s/step - loss: 0.6841 - acc: 0.5714 - val_loss: 0.6849 - val_acc: 0.6052\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc22f72a438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "_zRUnwb6Zkro",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "#Show a new image - an image that you want to test out on the model\n",
        "from IPython.display import Image\n",
        "#Image(\"./newimages/bunny3.jpg\")\n",
        "\n",
        "#To make predictions on a the new image\n",
        "#target_size ‘squishes’ the photos down to appropriate size.\n",
        "#image.img_to_array converts a PIL (Python Imaging Library) image instance to a Numpy array.\n",
        "#np.expand_dims(a,axis) expands the shape of an array. Insert a new axis that will appear at the axis position in the expanded array shape. \n",
        "#classifier.predict(test_image) returns an array of integers\n",
        "#predict_classes (docs) outputs A numpy array of class predictions. Which in your model case, the index of neuron of highest activation from your last(softmax) layer. [[0]] means that your model predicted that your test data is class 0. (usually you will be passing multiple image, and the result will look like [[0], [1], [1], [0]])\n",
        "#e.g You must convert your actual label (e.g. 'cancer', 'not cancer') into binary encoding (0 for 'cancer', 1 for 'not cancer') for binary classification. Then you will interpret your sequence output of [[0]] as having class label 'cancer'\n",
        "\n",
        "test_image = image.load_img('./train/d4.jpg', target_size = (256, 256))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = classifier.predict(test_image)\n",
        "\n",
        "#Training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'\n",
        "    \n",
        "print(result)\n",
        "print(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AzvvyDgvlv14",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
