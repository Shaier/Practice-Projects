{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN Practice (Cats/Dogs dataset).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "3cpoEfeN3xEA",
        "colab_type": "code",
        "outputId": "1a1cf238-c42f-4fa1-c111-73de63166a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Mount my drive- run the code, go to the link, accept.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t6pbZsB332vr",
        "colab_type": "code",
        "outputId": "7dfac464-746a-4e07-e1fe-a29ecc76d755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Change working directory to make it easier to access the files- (Folder inside of Colab- CNN folder- Images- Train/Test folder- Inside of each there are bunny/dog folders) \n",
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs\")\n",
        "os.getcwd() "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "AYGNWxHZ36RN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from __future__ import print_function, division\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import time\n",
        "import h5py\n",
        "import csv\n",
        "\n",
        "from scipy.misc import imresize, imsave\n",
        "\n",
        "from sklearn.metrics import log_loss, confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from PIL import Image, ImageChops, ImageOps\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.optimizers import RMSprop\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping, Callback\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, Activation, Dropout, Flatten, Dense, BatchNormalization\n",
        "#Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "# use ImageDataGenerator to preprocess the data\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9jM0GsnS6kut",
        "colab_type": "code",
        "outputId": "a080281d-7f67-4f0b-d71d-e0d8f047ffcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#Giving labels to the images: 1 for dog, 0 for cat\n",
        "\n",
        "path = \"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train\"\n",
        "files = os.listdir(path)\n",
        "categories = []\n",
        "\n",
        "for filename in files:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'dog':\n",
        "        categories.append(1)\n",
        "    elif category == 'cat':\n",
        "        categories.append(0)\n",
        "    else: pass\n",
        "df = pd.DataFrame({\n",
        "    'filename': files,\n",
        "    'category': categories\n",
        "})\n",
        "\n",
        "\n",
        "'''\n",
        "path_dogs = \"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train\"\n",
        "categories1 = []\n",
        "files_dogs = os.listdir(path_dogs)\n",
        "\n",
        "for filename in files_dogs:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'dog':\n",
        "        categories1.append(1)\n",
        "    else: pass\n",
        "df1 = pd.DataFrame({\n",
        "    'filename': files_dogs,\n",
        "    'category': categories1\n",
        "})\n",
        "\n",
        "path_cats= \"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train/Cats\"\n",
        "files_cats = os.listdir(path_cats)\n",
        "categories2 = []\n",
        "categories3=[]\n",
        "for filename in files_cats:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'cat':\n",
        "        categories2.append(0)\n",
        "    else:\n",
        "      categories3.append(filename)\n",
        "\n",
        "df3 = pd.DataFrame({\n",
        "    'filename': files_cats,\n",
        "    'category': categories2\n",
        "})\n",
        "\n",
        "frames=[df1,df3]\n",
        "df=pd.concat(frames)\n",
        "\n",
        "\n",
        "Deleting extra files\n",
        "import glob, os\n",
        "\n",
        "path_cats= \"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train/Cats\"\n",
        "files_cats = os.listdir(path_cats)\n",
        "\n",
        "for filename in files_cats:\n",
        "    if 'Copy' in filename:\n",
        "        #os.remove(\"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train/Cats/\"+filename)\n",
        "        print(\"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train/Cats/\"+filename)\n",
        "        '''"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\npath_dogs = \"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train\"\\ncategories1 = []\\nfiles_dogs = os.listdir(path_dogs)\\n\\nfor filename in files_dogs:\\n    category = filename.split(\\'.\\')[0]\\n    if category == \\'dog\\':\\n        categories1.append(1)\\n    else: pass\\ndf1 = pd.DataFrame({\\n    \\'filename\\': files_dogs,\\n    \\'category\\': categories1\\n})\\n\\npath_cats= \"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train/Cats\"\\nfiles_cats = os.listdir(path_cats)\\ncategories2 = []\\ncategories3=[]\\nfor filename in files_cats:\\n    category = filename.split(\\'.\\')[0]\\n    if category == \\'cat\\':\\n        categories2.append(0)\\n    else:\\n      categories3.append(filename)\\n\\ndf3 = pd.DataFrame({\\n    \\'filename\\': files_cats,\\n    \\'category\\': categories2\\n})\\n\\nframes=[df1,df3]\\ndf=pd.concat(frames)\\n\\n\\nDeleting extra files\\nimport glob, os\\n\\npath_cats= \"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train/Cats\"\\nfiles_cats = os.listdir(path_cats)\\n\\nfor filename in files_cats:\\n    if \\'Copy\\' in filename:\\n        #os.remove(\"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train/Cats/\"+filename)\\n        print(\"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train/Cats/\"+filename)\\n        '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "0arK1jiaSsdE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#move cats, dogs images to \"train\" folder\n",
        "'''\n",
        "import os, shutil\n",
        "\n",
        "topath = \"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train\"\n",
        "movedog = \"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train/Dogs\"\n",
        "movecat='/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train/Cats'\n",
        "\n",
        "files1 = os.listdir(movedog)\n",
        "files1.sort()\n",
        "for f in files1:\n",
        "  if \"dog\" in f:\n",
        "    src = os.path.join(movedog, f)\n",
        "    dst = os.path.join(topath, f)\n",
        "    shutil.move(src,dst)\n",
        "  else: pass\n",
        "\n",
        "files2 = os.listdir(movecat)\n",
        "files2.sort()\n",
        "for f in files2:\n",
        "  if \"cat\" in f:\n",
        "    src = os.path.join(movecat, f)\n",
        "    dst = os.path.join(topath, f)\n",
        "    shutil.move(src,dst)\n",
        "  else: pass\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sq58_3pv_Vy1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Bar chart for the categories\n",
        "df['category'].value_counts().plot.bar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "upz722JPrEvG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df=shuffle(df)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EkJZsy9ormoS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Prepare Test and Train Data\n",
        "\n",
        "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
        "\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)\n",
        "\n",
        "train_df['category'].value_counts().plot.bar()\n",
        "\n",
        "total_train = train_df.shape[0] #the number of images in the training df\n",
        "total_validate = validate_df.shape[0]  #the number of images in the validate df\n",
        "batch_size=15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i0Nl6ifrIuxa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#FAST_RUN = False\n",
        "IMAGE_WIDTH=50\n",
        "IMAGE_HEIGHT=50\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3 # RGB color\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ju6hykFhsPj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fce80af4-05bb-4ecb-ebf0-f46d2f1a7429"
      },
      "cell_type": "code",
      "source": [
        "#Traning Generator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df, \n",
        "    \"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train\", \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='binary',\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_rDHbfACsXKW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9ed22cc-1253-4952-9721-25f138160bbe"
      },
      "cell_type": "code",
      "source": [
        "#Validation Generator\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    validate_df, \n",
        "    \"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train/\", \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='binary',\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2PLPJpl1sgHX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#See how our generator work\n",
        "\n",
        "example_df = train_df.sample(n=1).reset_index(drop=True)\n",
        "example_generator = train_datagen.flow_from_dataframe(\n",
        "    example_df, \n",
        "    \"/content/gdrive/My Drive/Colab Notebooks/Cats_Vs_Dogs/train\", \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(0, 15):\n",
        "    plt.subplot(5, 3, i+1)\n",
        "    for X_batch, Y_batch in example_generator:\n",
        "        image = X_batch[0]\n",
        "        plt.imshow(image)\n",
        "        break\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H-vOX5D4L9Sz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Early Stop\n",
        "earlystop = EarlyStopping(patience=10)\n",
        "\n",
        "#Learning Rate Reduction\n",
        "#We will reduce the learning rate when then accuracy not increase for 2 steps\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oGSV10jaO3JU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "validate_df['category'].value_counts().plot.bar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nwhNE3WeQDMh",
        "colab_type": "code",
        "outputId": "0d11685c-992e-4394-a5a6-4e68bca7b659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1003
        }
      },
      "cell_type": "code",
      "source": [
        "#Fit Model\n",
        "#epochs=3 if FAST_RUN else 25\n",
        "history = model.fit_generator(\n",
        "    train_generator, \n",
        "    epochs=25,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_validate//batch_size,\n",
        "    steps_per_epoch=total_train//batch_size,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1333/1333 [==============================] - 667s 501ms/step - loss: 0.6517 - acc: 0.6670 - val_loss: 0.6208 - val_acc: 0.6649\n",
            "Epoch 2/25\n",
            "1333/1333 [==============================] - 665s 499ms/step - loss: 0.5386 - acc: 0.7273 - val_loss: 1.4934 - val_acc: 0.5890\n",
            "Epoch 3/25\n",
            "1333/1333 [==============================] - 664s 498ms/step - loss: 0.4975 - acc: 0.7590 - val_loss: 0.5220 - val_acc: 0.7649\n",
            "Epoch 4/25\n",
            "1333/1333 [==============================] - 666s 499ms/step - loss: 0.4773 - acc: 0.7688 - val_loss: 0.6721 - val_acc: 0.6983\n",
            "Epoch 5/25\n",
            "1333/1333 [==============================] - 657s 493ms/step - loss: 0.4545 - acc: 0.7824 - val_loss: 0.5014 - val_acc: 0.7633\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 6/25\n",
            "1333/1333 [==============================] - 660s 495ms/step - loss: 0.4236 - acc: 0.8047 - val_loss: 0.4775 - val_acc: 0.7793\n",
            "Epoch 7/25\n",
            "1333/1333 [==============================] - 654s 491ms/step - loss: 0.4076 - acc: 0.8154 - val_loss: 0.4067 - val_acc: 0.8072\n",
            "Epoch 8/25\n",
            "1333/1333 [==============================] - 661s 496ms/step - loss: 0.3953 - acc: 0.8161 - val_loss: 0.4471 - val_acc: 0.8126\n",
            "Epoch 9/25\n",
            "1333/1333 [==============================] - 649s 487ms/step - loss: 0.3854 - acc: 0.8197 - val_loss: 0.3918 - val_acc: 0.8245\n",
            "Epoch 10/25\n",
            "1333/1333 [==============================] - 362s 271ms/step - loss: 0.3803 - acc: 0.8267 - val_loss: 0.4158 - val_acc: 0.8173\n",
            "Epoch 11/25\n",
            "1333/1333 [==============================] - 357s 268ms/step - loss: 0.3777 - acc: 0.8279 - val_loss: 0.5491 - val_acc: 0.7938\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 12/25\n",
            "1333/1333 [==============================] - 358s 268ms/step - loss: 0.3555 - acc: 0.8416 - val_loss: 0.3724 - val_acc: 0.8385\n",
            "Epoch 13/25\n",
            "1333/1333 [==============================] - 363s 272ms/step - loss: 0.3473 - acc: 0.8423 - val_loss: 0.4351 - val_acc: 0.8114\n",
            "Epoch 14/25\n",
            "1333/1333 [==============================] - 362s 272ms/step - loss: 0.3389 - acc: 0.8501 - val_loss: 0.4076 - val_acc: 0.8158\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 15/25\n",
            "1333/1333 [==============================] - 355s 267ms/step - loss: 0.3301 - acc: 0.8526 - val_loss: 0.4992 - val_acc: 0.8004\n",
            "Epoch 16/25\n",
            "1333/1333 [==============================] - 358s 269ms/step - loss: 0.3230 - acc: 0.8560 - val_loss: 0.3897 - val_acc: 0.8327\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 17/25\n",
            "1333/1333 [==============================] - 360s 270ms/step - loss: 0.3147 - acc: 0.8608 - val_loss: 0.3821 - val_acc: 0.8355\n",
            "Epoch 18/25\n",
            "1333/1333 [==============================] - 362s 272ms/step - loss: 0.3152 - acc: 0.8590 - val_loss: 0.3881 - val_acc: 0.8331\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 19/25\n",
            "1333/1333 [==============================] - 367s 275ms/step - loss: 0.3089 - acc: 0.8661 - val_loss: 0.3756 - val_acc: 0.8383\n",
            "Epoch 20/25\n",
            "1333/1333 [==============================] - 357s 268ms/step - loss: 0.3076 - acc: 0.8657 - val_loss: 0.3886 - val_acc: 0.8295\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "Epoch 21/25\n",
            "1333/1333 [==============================] - 358s 269ms/step - loss: 0.3042 - acc: 0.8657 - val_loss: 0.3959 - val_acc: 0.8317\n",
            "Epoch 22/25\n",
            "1333/1333 [==============================] - 360s 270ms/step - loss: 0.3024 - acc: 0.8681 - val_loss: 0.3792 - val_acc: 0.8377\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1e-05.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RtirNwANc-xe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Save Model\n",
        "\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "\n",
        "## load weights into new model\n",
        "#loaded_model.load_weights(\"model.h5\")\n",
        "#print(\"Loaded model from disk\")\n",
        "\n",
        "# evaluate loaded model on test data\n",
        "#loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "#score = loaded_model.evaluate(X, Y, verbose=0)\n",
        "#print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zdlKkSJfcpkv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Virtualize Training\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
        "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
        "ax1.set_xticks(np.arange(1, 25, 1))\n",
        "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
        "\n",
        "ax2.plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
        "ax2.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
        "ax2.set_xticks(np.arange(1, 25, 1))\n",
        "\n",
        "legend = plt.legend(loc='best', shadow=True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B__hwkLDdMGn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Prepare Testing Data\n",
        "test_filenames = os.listdir(\"../input/test1/test1\")\n",
        "test_df = pd.DataFrame({\n",
        "    'filename': test_filenames\n",
        "})\n",
        "nb_samples = test_df.shape[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vTPNO7BgdOtB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create Testing Generator\n",
        "test_gen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_gen.flow_from_dataframe(\n",
        "    test_df, \n",
        "    \"../input/test1/test1/\", \n",
        "    x_col='filename',\n",
        "    y_col=None,\n",
        "    class_mode=None,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UYOlHJE4dRm_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Predict\n",
        "predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))\n",
        "\n",
        "#As predicted of binary classification result return probability that image likely to be a dog. \n",
        "#So we will have threshold 0.5 which mean if predicted value more than 50% it is a dog and under 50% will be a cat."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M8YEQObadT0c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "test_df['probability'] = predict\n",
        "test_df['category'] = np.where(test_df['probability'] > threshold, 1,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rpi4etnxdadi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Virtaulize Result\n",
        "test_df['category'].value_counts().plot.bar()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dj4AQ5VNdcuD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#See predicted result with images\n",
        "sample_test = test_df.head(18)\n",
        "sample_test.head()\n",
        "plt.figure(figsize=(12, 24))\n",
        "for index, row in sample_test.iterrows():\n",
        "    filename = row['filename']\n",
        "    category = row['category']\n",
        "    probability = row['probability']\n",
        "    img = load_img(\"../input/test1/test1/\"+filename, target_size=IMAGE_SIZE)\n",
        "    plt.subplot(6, 3, index+1)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' '(' + \"{}\".format(round(probability, 2)) + ')')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EiqwFdXHdg8v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Submission\n",
        "submission_df = test_df.copy()\n",
        "submission_df['id'] = submission_df['filename'].str.split('.').str[0]\n",
        "submission_df['label'] = submission_df['category']\n",
        "submission_df.drop(['filename', 'category'], axis=1, inplace=True)\n",
        "submission_df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}